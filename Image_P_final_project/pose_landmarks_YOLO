from ultralytics import YOLO
import numpy as np
import mediapipe as mp
import joblib 
import cv2
import torch
# import xgboost as xgb

yolo = YOLO('yolov8n.pt')
if torch.cuda.is_available():
    yolo.to('cuda')
    print("YOLO model moved to GPU.")
else:
    print("CUDA not available. YOLO model will run on CPU.")

print(f"YOLO model device: {yolo.device}")

#xgb_model = joblib.load('/home/soheil/Downloads/fall_detection_model.pkl')
try:
    xgb_model = joblib.load("/home/soheil/Downloads/fall_detection_model.pkl")
    print("Fall detection model loaded successfully.")
except FileNotFoundError:
    print("Error: 'fall_model.pkl' not found. Please ensure the model file is in the correct directory.")
    exit()

mp_pose = mp.solutions.pose
pose = mp_pose.Pose(static_image_mode=False) # initialize the pose estimation model
mp_drawing = mp.solutions.drawing_utils # draw the pose landmarksb

# def to extract pose landmarks
def extract_pose_landmarks(image):
    rgb_img = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    results = pose.process(rgb_img)
    if not results.pose_landmarks:
        return None, None ## add another None
    
    landmarks = results.pose_landmarks.landmark
    features = []
    for lm in landmarks:
        features.extend([lm.x, lm.y, lm.z, lm.visibility])
    if len(features) != 132:
        print(f"Warning: Expected 132 features, but got {len(features)}. Skipping this person.")
        return None, None
    
    return np.array(features).reshape(1,-1), results.pose_landmarks
    #return features
    
webcam = cv2.VideoCapture(0)
webcam.set(cv2.CAP_PROP_FRAME_WIDTH, 1920)
webcam.set(cv2.CAP_PROP_FRAME_HEIGHT, 1080)

while webcam.isOpened():
    ret, frame = webcam.read()
    if not ret:
        break
    frame = cv2.flip(frame, 1) # mirror horizontally

    results = yolo.predict(frame, classes = [0], conf = 0.4, verbose = False)
    detections = results[0].boxes.xyxy.cpu().numpy()   # extract bounding box coordinates (x1, y1, x2, y2)

    for det in detections:
        x1, y1, x2, y2 = map(int, det) # converts coordinates to integers
        x1 = max(0, x1)
        y1 = max(0, y1)
        x2 = min(frame.shape[1], x2)
        y2 = min(frame.shape[0], y2)
        
        person_img = frame[y1:y2, x1:x2] # extract region of interest of person image
        
        if person_img.shape[0] == 0 or person_img.shape[1] == 0 or person_img.shape[0] < 50 or person_img.shape[1] < 50:
            continue

        features, pose_landmarks_to_draw = extract_pose_landmarks(person_img) # call the function to extract pose landmark from person ROI
        label = "No Pose"
        color = (255, 0, 0)

        # if pose landmarks were extracted successfuly  --> predict fall staus using pretrained xgboost model
        if features is not None:
            try:
                prediction = xgb_model.predict(features)[0]
                label = "Fall" if prediction == "fall" or prediction == 1 else "Normal"
                color = (0, 0, 255) if label == "Fall" else (0, 255, 0)

                # draw mediapipe pose landmarks on the original frame
                roi_display = np.zeros_like(person_img)
                mp_drawing.draw_landmarks(
                    roi_display,
                    pose_landmarks_to_draw,
                    mp_pose.POSE_CONNECTIONS,
                    mp_drawing.DrawingSpec(color = (0, 0, 255), thickness = 2, circle_radius = 2), # green dots
                    mp_drawing.DrawingSpec(color = (255, 255, 255), thickness = 2, circle_radius = 2), # yellow lines
                )
                frame[y1:y2, x1:x2] = cv2.addWeighted(frame[y1:y2, x1:x2], 1, roi_display, 0.7, 0)

            except Exception as e:
                label = "prediction error"
                color = (0 , 165, 255)
                print(f'prediction error for person: {e}')

        cv2.rectangle(frame, (x1,y1), (x2, y2), color, 2) # draw a bounding box around the person
        cv2.putText(frame, label, (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 2)
    
    cv2.imshow("Multi-Person Fall Detection", frame)
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

webcam.release()
cv2.destroyAllWindows()


